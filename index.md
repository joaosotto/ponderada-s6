# Melhoria de Requisitos Não Funcionais de Segurança em Sistemas Conversacionais

## Introdução

### Descrição do Problema

Os sistemas conversacionais baseados em Modelos de Linguagem (LLMs) têm se tornado cada vez mais populares em aplicações como chatbots, assistentes virtuais e plataformas de suporte ao cliente. No entanto, a segurança desses sistemas é uma preocupação crescente. Os LLMs podem ser suscetíveis a uma variedade de ameaças, como vazamentos de dados sensíveis, manipulação de entrada e saída, e injeção de dados.

A segurança é um requisito não funcional para garantir a integridade, confidencialidade e disponibilidade das informações tratadas pelos LLMs. Além disso, a proteção contra ataques e o manejo seguro das informações dos usuários são essenciais para manter a credibilidade e conformidade com regulamentações.

### Justificativas

Com a crescente adoção de LLMs em diversos setores, garantir a segurança desses sistemas é vital para prevenir ataques que podem comprometer dados sensíveis e a privacidade dos usuários. Segundo [Santos et al. (2023)](https://example.com), falhas na segurança dos sistemas conversacionais podem resultar em vazamentos de dados e violações de privacidade. Portanto, é imperativo implementar medidas eficazes para proteger esses sistemas contra tais ameaças.

